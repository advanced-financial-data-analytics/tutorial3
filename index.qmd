---
title: "Tutorial 3"
subtitle: "Smoothing and Forecasting in Financial Time Series"
author: "Barry Quinn"
date: "Last updated: `r Sys.Date()`"
repo-actions: [source]
format:
  html:
    code-fold: true
    embed-resources: true
    toc: true
    toc-depth: 3
    number-sections: true
    code-tools:
      source: https://github.com/advanced-financial-data-analytics/tutorial3
editor: visual
execute:
  echo: true
  warning: false
  message: false
---

```{r setup, include=FALSE}
# Load necessary libraries
library(tidyverse)
library(tidyquant)
library(TTR)       # Moving averages
library(signal)    # Savitzky-Golay filter
library(dlm)       # Kalman filter
library(forecast)  # ARIMA
library(tsfe)      # Optional dataset

# Set global chunk options
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

In this tutorial, you'll learn to:

1.  Retrieve and preprocess financial time-series data.
2.  Apply smoothing techniques: Moving Averages, Savitzky-Golay, Lowess, and Kalman filter.
3.  Fit an ARIMA model for forecasting, understanding its limitations.

We will use Apple Inc. (AAPL) daily adjusted closing prices from Yahoo Finance.

Why Smoothing?

-   Financial data is noisy with frequent fluctuations.
-   Smoothing removes short-term noise and highlights trends.
-   However, no smoothing method guarantees profitable signals in efficient markets.

Why Forecasting?

-   Financial price forecasting is difficult due to the random-walk hypothesis.
-   ARIMA is a useful time-series modelling technique.

# Data Setup

## Retrieve AAPL data

```{r}
getSymbols("AAPL", from = "2020-01-01", to = "2022-12-31", auto.assign = TRUE)
```

## Extract adjusted closing prices

```{r}
aapl_prices <- Cl(AAPL)

# View data
head(aapl_prices)
```

## Convert to tibble for ggplot

```{r}
aapl_df <- tibble(
  date  = index(aapl_prices),
  price = as.numeric(aapl_prices)
)

ggplot(aapl_df, aes(x = date, y = price)) +
  geom_line(color="steelblue") +
  labs(title="AAPL Adjusted Closing Prices", x=NULL, y="Price (USD)") +
  theme_minimal()
```

# Smoothing Methods

## Simple Moving Average (SMA)

The Simple Moving Average (SMA) calculates the arithmetic mean of prices over a specified window (n days). Each point gets equal weight (1/n), making it the most basic smoothing technique. While simple, it has two key economic implications:
- It treats recent and old prices equally, which may not reflect market efficiency
- The lag is approximately (n+1)/2 days, making it a lagging indicator
- Commonly used windows are 20 days (monthly), 50 days (quarterly), and 200 days (yearly)

```{r}
sma_20 <- SMA(aapl_prices, n = 20)

df_sma <- tibble(
  date  = index(aapl_prices),
  price = as.numeric(aapl_prices),
  sma20 = as.numeric(sma_20)
)

ggplot(df_sma, aes(x=date)) +
  geom_line(aes(y=price), color="black") +
  geom_line(aes(y=sma20), color="red", size=0.9) +
  labs(title="Simple Moving Average (SMA) - 20 Day", x=NULL, y="Price (USD)") +
  theme_minimal()
```

> Question: How does the SMA compare in volatility reduction?

## Exponential Moving Average (EMA)

The EMA assigns exponentially decreasing weights to older observations, giving more importance to recent prices. The smoothing factor Î± = 2/(n+1) determines the rate of decay:
- More responsive to recent price changes than SMA, better reflecting market efficiency
- Reduces lag while maintaining smoothing properties
- The effective "memory" of the indicator extends infinitely but with rapidly diminishing weights

```{r}
ema_20 <- EMA(aapl_prices, n=20)

df_ema <- tibble(
  date  = index(aapl_prices),
  price = as.numeric(aapl_prices),
  ema20 = as.numeric(ema_20)
)

ggplot(df_ema, aes(x=date)) +
  geom_line(aes(y=price), color="black") +
  geom_line(aes(y=ema20), color="blue", size=0.9) +
  labs(title="Exponential Moving Average (EMA) - 20 Day", x=NULL, y="Price (USD)") +
  theme_minimal()
```

# Exercise: Compare the lag and responsiveness of SMA vs. EMA.

## Weighted Moving Average (WMA)

The WMA applies linear weights to prices, with recent observations getting higher weights. Unlike EMA's exponential decay:
- Provides a middle ground between SMA and EMA in terms of responsiveness
- Weights typically decline arithmetically (e.g., 5,4,3,2,1)
- Has a finite memory determined by the window size
- Often used in technical analysis for price momentum studies

```{r}
weights <- c(1,2,3,4,5)
weights <- weights/sum(weights)

wma_5 <- WMA(aapl_prices, n=5, wts=weights)

df_wma <- tibble(
  date   = index(aapl_prices),
  price  = as.numeric(aapl_prices),
  wma_5  = as.numeric(wma_5)
)

ggplot(df_wma, aes(x=date)) +
  geom_line(aes(y=price), color="black") +
  geom_line(aes(y=wma_5), color="green", size=0.9) +
  labs(title="Weighted Moving Average (5-Day)", x=NULL, y="Price (USD)") +
  theme_minimal()
```

## Savitzky-Golay Filter

The Savitzky-Golay filter fits a polynomial of degree p to n points around each data point using least squares. Unlike moving averages:
- Preserves higher moments (peaks, valleys) better than traditional moving averages
- Particularly useful for identifying trend reversals in price movements
- The polynomial degree p controls smoothness vs. feature preservation
- Often used in high-frequency trading for noise reduction

```{r}
sg_filter <- sgolayfilt(as.numeric(aapl_prices), p=3, n=21)

df_sg <- tibble(
  date  = index(aapl_prices),
  price = as.numeric(aapl_prices),
  sg    = as.numeric(sg_filter)
)

ggplot(df_sg, aes(x=date)) +
  geom_line(aes(y=price), color="black") +
  geom_line(aes(y=sg), color="purple", size=0.9) +
  labs(title="Savitzky-Golay Filter (p=3, n=21)", x=NULL, y="Price (USD)") +
  theme_minimal()
```

## Lowess Smoothing

Locally Weighted Scatterplot Smoothing (LOWESS) fits a polynomial regression to local neighborhoods of points:
- Adapts to local price volatility better than global smoothers
- The bandwidth parameter f controls the size of the local neighborhood
- Robust to outliers through iterative reweighting
- Particularly useful for identifying long-term market trends while adapting to changing volatility regimes

```{r}
df_lo_in <- tibble(
  x  = as.numeric(index(aapl_prices)),
  y  = as.numeric(aapl_prices)
)

lo_out <- lowess(df_lo_in$x, df_lo_in$y, f=0.1)

df_lo <- tibble(
  date  = as.Date(df_lo_in$x, origin="1970-01-01"),
  price = df_lo_in$y,
  lo    = lo_out$y
)

ggplot(df_lo, aes(x=date)) +
  geom_line(aes(y=price), color="black") +
  geom_line(aes(y=lo), color="orange", size=0.9) +
  labs(title="Lowess Smoothing (f=0.1)", x=NULL, y="Price (USD)") +
  theme_minimal()
```

## Kalman Filter

The Kalman filter is a recursive Bayesian estimator that combines a prediction model with noisy measurements:
- Optimal for linear systems with Gaussian noise
- Adapts dynamically to changing market volatility
- Parameters dV (measurement noise) and dW (process noise) control smoothing strength
- Particularly useful for real-time trading as it provides both filtered estimates and prediction uncertainties

```{r}
mod_poly <- dlmModPoly(order=1, dV=15100, dW=1470)
kf_smooth <- dlmSmooth(as.numeric(aapl_prices), mod_poly)

df_kf <- tibble(
  date    = index(aapl_prices),
  price   = as.numeric(aapl_prices),
  kalman  = dropFirst(kf_smooth$s)
)

ggplot(df_kf, aes(x=date)) +
  geom_line(aes(y=price, color="Price"), size=0.7) +
  geom_line(aes(y=kalman, color="blue"), size=0.9) +
  labs(title="Kalman Filter Smoothing", x=NULL, y="Price (USD)") +
  scale_color_manual(name="", values=c("Price"="black","Kalman"="blue")) +
  theme_minimal()
```

## ARIMA Forecast

ARIMA (Autoregressive Integrated Moving Average) models combine three components:
- AR(p): Autoregressive component capturing price dependencies
- I(d): Integration/differencing for stationarity
- MA(q): Moving average component for error structure

The model is denoted as ARIMA(p,d,q) where:
- p: Number of lagged returns affecting current return
- d: Number of times we difference prices to achieve stationarity
- q: Number of lagged error terms in the model

### Creating a Time-Series Object

We create a time series object with 252 trading days per year:

```{r}
aapl_ts <- ts(as.numeric(aapl_prices), frequency = 252, start = c(2020, as.numeric(format(start(aapl_prices), "%j"))))
```

### ARIMA Model

The auto.arima() function automatically selects optimal p, d, q values by minimizing AIC/BIC:
- Tests for stationarity and determines appropriate differencing
- Searches over possible AR and MA orders
- Includes drift terms if beneficial
- Uses maximum likelihood estimation for parameters

```{r}
fit_arima <- auto.arima(aapl_ts)
summary(fit_arima)
```

### Forecasting

We generate 20-day ahead forecasts with prediction intervals:
- Point forecasts are conditional expectations
- Intervals widen with horizon, reflecting increasing uncertainty
- Blue = point forecast
- Dark gray = 80% prediction interval
- Light gray = 95% prediction interval

```{r}
future_fc <- forecast(fit_arima, h=20)

autoplot(future_fc) +
  labs(title="ARIMA Forecast: AAPL", x="Trading Days", y="Price (USD)") +
  theme_minimal()
```

# Exercises

1.  Compare smoothing methods:

-   Which method is fastest at reacting to sudden price jumps?
-   Which is slowest and smoothest?

2.  Experiment with ARIMA forecasts:

-   Does it revert to a drift term?
-   How does adjusting the time window affect the fit?

# Wrap-Up

-   Financial prices are noisy; smoothing highlights trends but does not create profitable signals.
-   ARIMA models are useful but often resemble random-walk structures.
-   Advanced methods (GARCH, ML) may offer better predictive power.